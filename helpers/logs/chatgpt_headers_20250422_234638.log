2025-04-22 23:46:38,802 - __main__ - INFO - Starting GetChatGPTHeaders
2025-04-22 23:46:39,343 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello, world!'}], 'model': 'gpt-3.5-turbo'}}
2025-04-22 23:46:39,386 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-04-22 23:46:39,387 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-22 23:46:39,480 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002206C9DC790>
2025-04-22 23:46:39,480 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002206C7F6D40> server_hostname='api.openai.com' timeout=5.0
2025-04-22 23:46:39,497 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002206C9DC820>
2025-04-22 23:46:39,497 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-22 23:46:39,498 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-22 23:46:39,498 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-22 23:46:39,499 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-22 23:46:39,499 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-22 23:46:39,559 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 23 Apr 2025 03:46:36 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_4fe3d3fe5fd7b0f7249773c62ed89527'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VOxpHieLx57ILPiFE1MaND7WRdeggfm1KFZ8fiA1eZQ-1745379996-1.0.1.1-GVb2Mz2hOF6HJVn.EjVBcrUjBNvdBn4GH5BFscXRM3.EHLqQps8K2D82FB2x9_Fs86kx9siBTzCZ0..rhQLbHM7hVJdmoy8QYYCLG5nrJ68; path=/; expires=Wed, 23-Apr-25 04:16:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4CXqoEXImMPsVbLZMNHMx.l8iTNgmnWaBdHZtYptk1Y-1745379996238-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'934a5ff03c3d3b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-22 23:46:39,562 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 23:46:39,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-22 23:46:39,562 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-22 23:46:39,563 - httpcore.http11 - DEBUG - response_closed.started
2025-04-22 23:46:39,563 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-22 23:46:39,563 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 23 Apr 2025 03:46:36 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_4fe3d3fe5fd7b0f7249773c62ed89527'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=VOxpHieLx57ILPiFE1MaND7WRdeggfm1KFZ8fiA1eZQ-1745379996-1.0.1.1-GVb2Mz2hOF6HJVn.EjVBcrUjBNvdBn4GH5BFscXRM3.EHLqQps8K2D82FB2x9_Fs86kx9siBTzCZ0..rhQLbHM7hVJdmoy8QYYCLG5nrJ68; path=/; expires=Wed, 23-Apr-25 04:16:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4CXqoEXImMPsVbLZMNHMx.l8iTNgmnWaBdHZtYptk1Y-1745379996238-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '934a5ff03c3d3b8e-BOS'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-04-22 23:46:39,564 - openai._base_client - DEBUG - request_id: req_4fe3d3fe5fd7b0f7249773c62ed89527
2025-04-22 23:46:39,565 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\dan\miniconda3\envs\ragentenv\lib\site-packages\openai\_base_client.py", line 1002, in _request
    response.raise_for_status()
  File "C:\Users\dan\miniconda3\envs\ragentenv\lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-04-22 23:46:39,567 - openai._base_client - DEBUG - Re-raising status error
2025-04-22 23:46:39,569 - call_ChatGPT - ERROR - Unexpected error in OpenAI call: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 23:46:39,569 - __main__ - INFO - 
 OpenAI Rate Limit Headers:
2025-04-22 23:46:39,570 - __main__ - ERROR - Empty response from OpenAI
2025-04-22 23:46:39,612 - httpcore.connection - DEBUG - close.started
2025-04-22 23:46:39,613 - httpcore.connection - DEBUG - close.complete
