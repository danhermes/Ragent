2025-04-22 23:38:55,286 - __main__ - INFO - Starting GetChatGPTHeaders
2025-04-22 23:38:55,829 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Hello, world!'}], 'model': 'gpt-3.5-turbo'}}
2025-04-22 23:38:55,872 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-04-22 23:38:55,873 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-04-22 23:38:55,971 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025976370850>
2025-04-22 23:38:55,971 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025976186CC0> server_hostname='api.openai.com' timeout=5.0
2025-04-22 23:38:56,002 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000259763708E0>
2025-04-22 23:38:56,004 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-04-22 23:38:56,007 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-04-22 23:38:56,008 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-04-22 23:38:56,009 - httpcore.http11 - DEBUG - send_request_body.complete
2025-04-22 23:38:56,010 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-04-22 23:38:56,069 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Wed, 23 Apr 2025 03:38:52 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_209571b27dfbc74914274505c1938705'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.VfjMrx5sD5q5SyzoVZBaIEbkV5peKDlDkDjIC1NXlk-1745379532-1.0.1.1-OVn4c_buuyY6rQH1m4n1VjizSSbssHh0bgGzhEYV_6hWQKn56xaKsBmYicQODmtAZ5cRoOfGmy4Goz4Td5PlqKgQ32vtgoxfr0uw0Erhxeg; path=/; expires=Wed, 23-Apr-25 04:08:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=zw4kk2qGSeOknWhPwiwJMkznK3q5GI7qaujzsNuaWFI-1745379532769-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'934a549f8c559062-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-04-22 23:38:56,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-04-22 23:38:56,072 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-04-22 23:38:56,072 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-04-22 23:38:56,072 - httpcore.http11 - DEBUG - response_closed.started
2025-04-22 23:38:56,073 - httpcore.http11 - DEBUG - response_closed.complete
2025-04-22 23:38:56,073 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers([('date', 'Wed, 23 Apr 2025 03:38:52 GMT'), ('content-type', 'application/json; charset=utf-8'), ('content-length', '337'), ('connection', 'keep-alive'), ('vary', 'Origin'), ('x-request-id', 'req_209571b27dfbc74914274505c1938705'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.VfjMrx5sD5q5SyzoVZBaIEbkV5peKDlDkDjIC1NXlk-1745379532-1.0.1.1-OVn4c_buuyY6rQH1m4n1VjizSSbssHh0bgGzhEYV_6hWQKn56xaKsBmYicQODmtAZ5cRoOfGmy4Goz4Td5PlqKgQ32vtgoxfr0uw0Erhxeg; path=/; expires=Wed, 23-Apr-25 04:08:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=zw4kk2qGSeOknWhPwiwJMkznK3q5GI7qaujzsNuaWFI-1745379532769-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '934a549f8c559062-BOS'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-04-22 23:38:56,074 - openai._base_client - DEBUG - request_id: req_209571b27dfbc74914274505c1938705
2025-04-22 23:38:56,075 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\dan\miniconda3\envs\ragentenv\lib\site-packages\openai\_base_client.py", line 1002, in _request
    response.raise_for_status()
  File "C:\Users\dan\miniconda3\envs\ragentenv\lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-04-22 23:38:56,077 - openai._base_client - DEBUG - Re-raising status error
2025-04-22 23:38:56,079 - call_ChatGPT - ERROR - Unexpected error in OpenAI call: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-04-22 23:38:56,079 - __main__ - INFO - 
 OpenAI Rate Limit Headers:
2025-04-22 23:38:56,080 - __main__ - ERROR - Empty response from OpenAI
2025-04-22 23:38:56,125 - httpcore.connection - DEBUG - close.started
2025-04-22 23:38:56,125 - httpcore.connection - DEBUG - close.complete
